#import "@preview/timeliney:0.0.1"
#import "@preview/modern-technique-report:0.1.0": *

/*
headers and footers
*/
// colours!!!! use these for formatting colours :)
#let themegradientcolour = color.map.plasma
#let themegradient = gradient.linear(..themegradientcolour)
#let doubletheme = (..color.map.plasma, ..color.map.plasma)
#let lastheading = "None"

#set page(
  // footer
  footer: context {
    if counter(page).get().first() > 0 [   
      #text(size:0.85em)[
        #h(1fr)
        #counter(page).display() 
      ]
    ]
  },
  
  // header
  header: context {
    let before = query(selector(heading.where(level:1)).before(here()))
    let after = query(selector(heading.where(level:1)).after(here()))
    let section = if after.len() == 0 {
      // show previous if in last section
      before.last().body
    } else if before.len() == 0 { 
      // show "Western University" if we haven't reached the first section
      [Western University]
    } else if after.first().location().page() == here().page() {
      // if new section is on this page, show that new section
      after.first().body
    } else {
      // if no new section, show previous section
      before.last().body
    }
    /*
    let elems = query(heading.where(level:1))
    let section
    if elems.len() == 0 {section = [Western University]}
    else if elems.len() == query(heading.where(level:1)).len() {
      section = query(heading).last().body
    }
    else {section = elems.last().body}
    */
    // actual header lol
    if counter(page).get().first() > 0 [
      #place(top+left,dx:-200pt,
        rect(width: 180%, height:10pt, fill: themegradient)
      )
      #text(size:0.85em)[
        _SE Capstone Project Proposal 2024-2025_ 
        #h(1fr)
        #section        
      ]
    ]
  }
)

/*
cover page
*/
// set cover page to page 0
#counter(page).update(0)
// template to simplify things
#show: modern-technique-report.with(
  // title!!!
  title: {
    v(-2em)
    
    align(center)[#text(size: 50pt)[STELLA]\ #v(-.75em)#text(tracking: 1pt, size:10pt)[Simulated Training Environments\ #v(-5pt)and Large Learning Autonoma]]
},
  // subtitle???
  subtitle: {
    v(.5em)
    align(center)[#text(size:24pt)[Project Proposal]]
    v(0em)
  },
  // little block thing top left
  series: [SE 4450 Software Engineering Design II \
    Team 32 _Capstone Project_],
  // names :D
  author: [#set text(13pt);\ #grid(
    align: (left , left + horizon, right),
    columns: (1fr, 2fr, 1.5fr),
    inset: 6pt,
    [*_Members_*], [Beaudry Hajji, Isabelle],[ibeaudr\@uwo.ca],
    [],[Hoffman, Madelyn], [mhoffm32\@uwo.ca],
    [],[Bazina-Grolinger, Dominic],	[dbazinag\@uwo.ca],
    [],[Su, James], 	[tsu32\@uwo.ca],
    [*_Advisor_*], [Yimin Yang],[yimin.yang\@uwo.ca],
  )#place(bottom + right, dy:20pt)[#set text(15pt); *Western University*]],
  // date
  date: [\ \ #v(6pt)#rotate(9deg, [October 9, 2024])],
  
  // GRADIENT slice at the bottom
  background: [#rect(width: 100%,
  height:100%, fill: (gradient.conic(..color.map.rainbow)))],
  font: "Montserrat",
) 

// table of contents is auto generated by template 

// text settings
#set par(first-line-indent: 3em, justify: true, leading: 1em)
// gross fix for the stupid indent bug
// https://github.com/typst/typst/issues/311
#show heading: it => [#it #text(size:0.1em)[#h(0.0em)]#v(-0.1em)]

/*
introduction
*/
= Introduction and Problem Statement

Autonomous vehicles (AV) already offer promising advancements in safety, efficiency, and convenience, but still retain many issues 
that stifle guaranteed safety. 
The strict requirements and expectations of AV require it to far surpass human performance, but many advances are still yet to be made. This project aims to improve the development process of existing state of the art (SOTA) autonomous drivers (AD), through revisions of current techniques and integrations with simulated environments (SE).

North American transportation remains heavily car-centric, making many risks on the road difficult to avoid.
Driver error is the leading cause of these risks, accounting for 94% of incidents, while only 6% are caused by other reasons like malfunctions @nhtsa.
Reducing the risk of accidents would quickly benefit much of the population, possibly saving lives.

Another point of contention is environmental impact. 
In 2022, transportation accounted for nearly 28% of all greenhouse gas emissions in the United States: of which 57% comes from light duty vehicles @EPA2024. 
Improving driving techniques alone can advance efficiency and reduce emissions by as much as 25% @narcan.
While changing the driving habits of all drivers on the road is unlikely and difficult, AD can be designed be efficient from the start and be distributed to a large portion of vehicles on the road.

A major challenge for AV lies in their reponse to dangerous conditions. Sudden obstacles like pedestrians, or environmental dangers like hydroplaning can pose an imminent collision risk if handled improperly. 
AVs also must deal with many other risks; operation in various light and weather conditions, response to sensor faults, and maintaining quick processing times without delay @Stevens2018.
Some of these issues are difficult to combat, particularly in emergency scenarios, as real world testing can pose ethical dilemmas while large test facilities are often resource intensive to build. 

Public perception of AV remains an obstacle to its adoption, with concerns around safety and effectiveness @Stevens2018. 
Accidents involving AVs are scrutinised much more than those involving human drivers, as passengers often distrust AD.
As such, the accident rate involving AVs must be remarkably lower than human rates, before it can be expected to be widely adopted.

Core project ideals of STELLA include finding and filling gaps in the current understanding of AV. By assisting open source solutions, the goal is to make small but concrete contributions that advance the field as a whole.

/*
Background
*/
= Background
/*
- just spew some stuff from @AVFacts LOL
- carla stuff @carla
- LLM4AD @yang2024survey
- RL agents @Sutton1998
- road testing expensive / dangerous
- simulation accessibility
*/
// == The Demand for AVs
//Background for autonomous driving
//Explaining what AVs are

/* 
AVs are designed to navigate roads and traffic without human intervention, typically done using a combination of cameras, sensors fed into machine learning (ML) based techniques. 

AVs can be organised into six levels of automation ranging from level 0, where the driver is in full control, to level 5, where there is no need for a driver to even be inside the vehicle @AVFacts. 

Development of AVs began in the 1980s but this field really picked up steam when the U.S. Defense Advanced Research Projects Agency held a "grand challenge" in 2004 where they would test the performance of AVs on a 150-mile off-road course. No projects were successful in finishing the challenge in 2004, however, in 2005 and 2007 when they hosted this competition again many teams were able to complete both off-road and urban courses @AVFacts. 

The AV market has grown exponentially in the last few decades: in 2023 the AV market was estimated to grow to 13 trillion by 2030 @FBAVReport. 
Many car companies are competing for space in this industry with companies such as Tesla, Waymo, and General Motors currently leading the race @FBAVReport.
Evidently, there is a market demand for AVs and there are ample benefactors who could apply such technology. 
The field also concerns more than just cars and human transportation, as there are many applications elsewhere.
Shipping and logisitcs is one such application, as the usage of ADs could remove the downtime needed for humans to rest and recharge. 

Logistics carriers like Amazon use autonomous drones to deliver packages for their "Amazon Prime Air" service, Yara is making autonomous ships for cargo transport, Starship robots has made autonomous last-mile delivery robots, and many more companies are looking for ways to include similar technologies into their everyday operations.
*/

== Reinforcement Learning

Reinforcement learning (RL) is one of the common techniques in AVs.
Learning is often associated as the pairing of environment interaction with positive and negative feedback.
One example is classical conditioning, which Ivan Pavlov observed in lab dogs that learned to associate lab technicians with getting fed, resulting in them salivating at the sight of humans @conditioning.
RL tries to emulate classical conditioning, by mapping scalar values as positive and negative feedback which an agent tries to maximise @Sutton1998. 
As an often favoured technique, there are many modern modifications developed to further improve its results.

While modern implementations are quite complex, projects like pytorch @pytorch and stablebaselines-3 @stable3
allow end users to not only build but customise agents within minutes. 
This lowers the skill and experience necessary to get started, and allows projects to be built more quickly and efficiently.

== Current State of the Art
/*
- LLM4AD stuff
*/
In a literature review by Yang et al @yang2024survey, SOTA techniques often combine traditional approaches like RL and Large Language Models (LLMs), which have recently surged in popularity. 
Although the inner workings of LLMs are poorly understood, they have demonstrated capabilities in interpreting context and reasoning. Applications in AV's has shown notable performance, even winning in competitions against other techniques @competition.
Yang et al highlight several new techniques from 2023 and 2024, which integrate LLMs with traditional techniques that maximise performance across different sectors, including perception and control.

== Current Applied Forms 
/*
tesla etc
*/
While open source capabilites are well documented and publicly available, there also exist closed source solutions. 
Many automotive manufacturers like Tesla are pursuing their own AV implementations, and are less willing to provide details on their discoveries @FBAVReport.
While these results are not as easily reproduced, they do provide hints as to what capabilities are tested and known, and what has been well tested enough to be made available to consumers. More importantly, this highlights what still needs to be worked on and improved, based on what manufacturers are less willing to advertise.
Such domains include emergency response, as discussed in the introduction. Using a simulation will allow us to test and verify such conditions, and build towards a better general solution overall.

Current systems also rely on prebuilt maps that have been downloaded beforehand @AVFacts. While an connection can allow for fast updates, particularly in urban areas, ADs may get stuck if the real map no longer corresponds to its beliefs. Improvements in this area may not only improve AD capability in this respect, but also improve its decision making in other problems as well.

== Simulations
/*
carla
*/
Many open source solutions that are resource constrained often rely on simulations for the bulk of development. One such popular simulation is CARLA @carla. Introduced in 2017, CARLA is backed by many robotics research organisations, including the Toyota Research Institude. 
CARLA provides virtual sensors, maps, feedback, and is highly customisable as it is open source. 
Being built around Unreal 4, a highly popular physics and game engine, provides CARLA with a wealth of documentation and community support.

Another form of simulated training is through the generation of input data. Some of these can be generated conventionally, like adding noise and rotation to images. 
However, an increasing number of applications generate permutations of training data using generative neural network models @yang2024survey.
Caveats of this technique include bias towards datasets used to train these models, but they offer an easy and relatively robust solution to quickly obtaining more training data.

/*
objectives and scope
*/
= Objectives and Scope
The objective of STELLA is to develop a RL based AD agent, capable of navigating complext road scenarios, effectively utilising available resources and within the constraints of the project.

== Goals and Scope

The first stage of STELLA involves the formation of a process to first build the agent and integrate a minimal set of features. 
Once tested, the project then splits into two parts; tuning for separate, but optimal performance in the MAP and SENSORS competition tracks @competition.
Once the similarities and differences are explored, a new  agent can be rebuilt that has a more generalised skillset for both tracks.
These competition tracks are built for specific challenges, so modifications or even a new track may be a part of the project, expanding the range of qualities that can be assessed. 

In the process, new datasets could be collected, and new techniques may be implemented. While CARLA and stablebaselines-3 already provide many options, some new techniques may be relatively easy to implement but are not provided yet.
Subsequently, STELLA may involve submitting potential improvements to open source projects, including the CARLA simulator. 
Possible contributions include new noise generation options, simulation configuration options, or even just improving documentation and guides. 

== Constraints

As a student project, many constraints must be handled appropriately, including time restrictions, resources, and personnel. 
Project success requires attention and foresight to be properly managed.

Time constraints can be varying and unpredictable due to the nature of coursework, and some deadlines within a month of previous ones, or expect multiple deliverables to be completed within the same timeframe. 
Time coordiantion between team members without full time dedication can also be difficult to coordinate, as availability often does not overlap.
Within the rapid schedule of development, there is like little time to establish backwards compatible features and a stable API, so STELLA will be required to remain in development versions 0.y.z so as to adhere to semantic versioning guidelines @semver.
To reduce the strain of time constraints, the timeline is split into small acheivable goals with many milestones, lending itself easily to sprints and offering modularity to project planning. 

Resources are also constrained, particularly budget and facilities.
Testing with scale vehicles and real roads would provide the most accurate environment, but is not an option due to legal, financial, and moral restrictions. 
With the simulator CARLA @carla, the team will be able to simulate a wide range of driving scenarios, but these simulations may not fully capture the complexity and unpredictability of real-world environments. This limits the agent's exposure to certain edge cases and makes validation more challenging. 

Limited personnel availability and experience also limits targets.
A team of four part time members does not result in a large number of effective work hours, compared to what a larger organisation could complete in the same timeframe.
While the team does have some expertise in robotics, none of the members have a background in AD. 
As a result, a portion of time needs to be dedicated to learning introductory topics, and tutorials, we has been allocated on the schedule.
While this allows for a better projection of progress and provides time for adjusting, the lack of experience reduces the overall scope of the project acheivable.   


/*
methodology and process
*/
= Methodology and Process
== Methodology
STELLA applies RL to train an AD agent, with an emphasis on the  ability to handle complex or unexpected road situations.
// this was covered under objectives
/*
Significance is placed on developing the AD's capabilities for emergency maneuvers, to ensure that it can respond ideally to maximise safety when unexpected situations arise on the road. RL will facilitate the vehicle’s adaptive learning through trial and error by navigating various emergency scenarios, earning rewards for successful maneuvers—such as avoiding collisions—and receiving penalties for unsafe actions.
*/
CARLA will be used to design and build virtual driving environments, used for testing and refining the AD. 
//This approach allows for the simulation of emergency scenarios and varying driving conditions using a range of weather patterns and lighting situations. 
//By training our agent in a dynamic and diverse environment, we can enhance it's preparedness for a broad range of events and changing variables.
CARLA provides simulated sensor data, including devices like LiDAR and cameras. 
// we can add this to background if desired
//This feedback enhances the decision-making process, particularly in emergency situations, allowing the agent to respond more effectively to unexpected challenges on the road. Simulated sensor data from sources such as Light Detection and Ranging (LiDAR) will provide the agent with additional environmental feedback. Having a wide range of data to visualise the environment will improve the decision making process of the agent, allowing it to respond more effectively to emergencies and unexpected challenges on the road.

An incremental process will be used for both the development and testing of the project. The agent's training and development will begin with simpler road scenarios with increasing complexity as the agent's performance improves. This gradual progression will allow for a more refined evaluation and adjustment of the agent's capabilities.

Version control will be maintained and well documented for organisation of commits and features @convcomm.
Since development will be rapid with no backwards compatibility, STELLA will remain in major version 0.
This allows the team to pursue divergent modifications and combinations of techniques, which may accumulate into profuse parallel versions that need to be well organised and reversible.

== Process

The project begins with establishing a project structure, entailing specific compatible dependency versions for CARLA and its interface with the RL framework. 
This framework also needs to be configured with specific CUDA, pytorch, and stablebaselines-3 versions.
Part of RL also includes customising parameters for the AD to utilise as feedback. 
Finally, the two must be well integrated to work on the same machine or possible issues may arise like resource limitations.
//The RL agent will then be initialised by defining its structure and variables. The training environment will then be created by integrating CARLA within the RL framework which will be performed using CARLA's  Python API to simulate the vehicles behavior along with the environment while collecting sensor data. A reward system will be implemented to incentivise safe driving while correcting poor driving decision. 

//The agent will then be trained to interact within the CARLA environment, followed by testing and validation on Nvidia Jetson if time permits. Lastly, detailed documentation will be completed on the autonomous driving software and relevant development topics. 
Following proper project structure, a proof of concept can be built which generally follows the steps of:
1. Configure the specific simulation task and parameters
2. Train or provide a trained agent to use
3. Integrate the agent into the simulation
4. Evaluate and tweak performance 
These steps can be repeated for specific tasks that the agent needs to complete, such as emergency handling or incorrect navigation.
STELLA will initially use previously available tracks to expedite development, but may modify them to tackle specific features and abilities.
It follows that specialised agents are not as performant on other tasks, so final portion of the project reworks previous portions to be more generalisable, producing a single agent with all features for all tasks.



/*
deliverables
*/
= Deliverables
#v(-1em)
== Software
#v(-1em)
- Source code and version history
- Simulation environments / tasks
  - Settings, configurations, etc.
  - Note indeterminate systems for reproducibility 
- Model weights
  - Best final model
  - Notable checkpoints 
- Novel datasets

== Documents and Presentations
#v(-1em)
=== Submitted Documents and Presentations
#v(-1em)
- Project proposal
- Walkthrough
  - Sprint plan 1
  - Sprint plan 2
- Initial demonstration 
- Final demonstration
  - Video
  - Demonstration documents and files
  - Retrospection
=== Software Documentation 
#v(-1em)
- User guide
  - Installation
  - Configuration
  - CARLA integration and settings
- License

/*
project plan
*/
= Project Plan

== Matrix of Responsibilities
#let r_colour = rgb("#A42397")
#let a_colour = rgb("#C33F80")
#let c_colour = rgb("#DB5C69")
#let h_colour = rgb("#111")
#align(center)[
  #set table(
    stroke: none,
    gutter: 0.2em,
    inset: (x:10pt, y:5pt),
  )
  #let R_ = table.cell(
    fill: r_colour,
  )[#set text(white); Responsible]
  #let A_ = table.cell(
    fill: a_colour
  )[#set text(white); Accountable]
  #let C_ = table.cell(
    fill: c_colour,
  )[#set text(white); Coordinate]
  #show table.cell: it => {
    if it.x != 0 {set text(black)}
    else { set text(white) }
    it
  }
  
  #table(
    columns: 3,
    R_, A_, C_,
    [Work on Task], [Accountable for\ Leading Task ], [Working on \ Parallel Task]
  )
  
  #set table(
    stroke: none,
    gutter: 0.0pt,
    fill: (x, y) =>
      if y == 0 { rgb("#402040") }
      else if x == 0 { rgb("#2A0054")},
    inset: (x:25pt, y:8pt),
  )
  
  #show table.cell: it => {
    if it.x == 0 or it.y == 0 {
      set text(rgb("E5E5E5"))
      strong(it)
    } else if it.body == [] {
      // Replace empty cells with 'N/A'
    } else {
      set text(white)
      strong(it)
    }
  }
  #let R = table.cell(
    fill: r_colour,
  )[R]
  #let A = table.cell(
    fill: a_colour
  )[A]
  #let C = table.cell(
    fill: c_colour
  )[C]
  #let h(content) = table.cell(
    colspan: 5,
    align: horizon,
    inset: (y: 4pt),
    fill: h_colour,
  )[#text(size:8pt)[#content]]
  
  #table(
    columns: 5,
    [Task \\  Person], [I.B], [M.H.], [D.B], [J.S],
    h()[Documentation and Deliverables],
    [Proposal], A, R, R, R, 
    [Walkthrough], R, A, R, R,
    [Version Control], R, R, R, A,
    [Concept Demo], R, R, A, R, 
    [User Guide], R, A, R, R,
    [Final Demo], A, R, R, R,
    h()[Preliminaries],
    [Setup Environment], C, R, A, C, 
    [Setup Framework], R, C, C, A,
    h()[Proof of Concept],
    [Simulation Config], A, R, C, C,
    [Build Agent], C, C, A, R,
    [Integration], R, A, R, R,
    [Test and Validate], R, R, R, A,
    h()[Sprint 1#footnote()[Sprints will be segmented and designed in further detail in the corresponding report]<sprint>],
    [SENSORS Track@mixedlead], R, R, C, C,
    [MAPS Track@mixedlead], C, C, R, R,
    h()[Sprint 2<sprint>],
    [Combine Systems#footnote()[Different team members will lead separate subtasks specified in sprint planning.]<mixedlead>], R, R, R, R,
    [Optimizations@mixedlead], R, R, R, R,
  )
]

#pagebreak()
#let catlinecolour = themegradientcolour.slice(0,7)
#let linecolour = themegradientcolour.slice(2, 10) // after 10 it gets too florescent and hard to read

#place()[== Gantt Chart]
#place(center, dy: 18pt, dx: 0pt)[#rotate(90deg, reflow:true)[
  #timeliney.timeline(
    show-grid: true,
    grid-style: (
      stroke: (dash: "dashed", thickness: 0.2pt, paint: rgb("#555")),
    ),
    spacing: 4pt,
    line-style: (stroke: 3pt + gradient.linear(..catlinecolour)),
    {
      import timeliney: *
      headerline(group(([*2024*], 3)), group(([*2025*], 3)))
      headerline(
        group("Oct", "Nov", "Dec",),
        group("Jan", "Feb", "Mar"),
      )
      taskgroup(title: [*Docs and Deliv.*], {
        task("Proposal", (0, 0.28), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Walkthough & Plan", (0.28, 1.2), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Version Control", (1, 5.6), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Concept Demo", (1.6, 2.15), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("User Guide", (2, 5.6), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Final Demo", (4.2, 5.6), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })
      taskgroup(title: [*Prelim*], {
        task("Setup Envs", (0.3, 0.7), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Setup Framework", (0.6, 1.2), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })
      taskgroup(title: [*Version 0.0*], {
        task("Config Sim", (1, 1.5), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Build Agent", (1.2, 2), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Integrate", (1.5, 2), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Test and Validate", (1.9, 2.14), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })
      taskgroup(title: [*Version 0.1M*], {
        task("Adapt for Task", (2., 3.5), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("MAPS Track Opt.", (3., 3.8), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })
      taskgroup(title: [*Version 0.1S*], {
        task("Adapt for Task", (2., 3.5), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("SENSORS Track Opt.", (3., 3.8), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })
      taskgroup(title: [*Version 0.2*], {
        task("Combine System", (3.8, 4.2), style: (stroke: 2pt + gradient.linear(..linecolour)))
        task("Optimise Agent", (4.2, 5.6), style: (stroke: 2pt + gradient.linear(..linecolour)))
      })   
  
      milestone(
        at: (9/31),
        style: (stroke: (dash: "dashed")),
        align(center, [
          #h(10pt)*Project Proposal*#h(10pt)\
          Oct 2024
        ])
      )
      milestone(
        at: 1+(6/30),
        style: (stroke: (dash: "dashed")),
        align(center, [
          *Walkthrough &\ Sprint Plans* \
          Nov 2024
        ])
      )
      milestone(
        at: 2+(4/30),
        style: (stroke: (dash: "dashed")),
        align(center, [
          *Concept Demo* \
          Dec 2024
        ])
      )
      milestone(
        at: 3+(24/30),
        style: (stroke: (dash: "dashed")),
        align(center, [
          *End of Sprint 1* \
          Jan 2024
        ])
      )
      milestone(
        at: 5+(19/31),
        style: (stroke: (dash: "dashed")),
        align(center, [
          *End of Sprint 2:\ Final Demo, Presentation,\ & Retrospection* \
          Mar 2025
        ])
      )
    }
  )
]]

#heading(outlined: true, level: 1, numbering: (..nums) => [])[Terms]

/* template
AV      #h(1fr)   Autonomous Vehicle        \ 
*/
#pad(2em)[
AV      #h(1fr)   Autonomous Vehicle        \ 
SOTA    #h(1fr)   State Of The Art          \
AD      #h(1fr)   Autonomous Drivers        \ 
SE      #h(1fr)   Simulated Environment     \  
RL      #h(1fr)   Reinforcement Learning    \
LLM     #h(1fr)   Large Language Model      \
]

/*
Bibliography
*/
#set par(justify: false)
#bibliography("refs.bib", title: [References], style:"institute-of-electrical-and-electronics-engineers", full: false)
